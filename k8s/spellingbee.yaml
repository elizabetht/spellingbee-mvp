apiVersion: v1
kind: Namespace
metadata:
  name: spellingbee
---
# -----------------------
# UI Config (nginx + static files)
# -----------------------
apiVersion: v1
kind: ConfigMap
metadata:
  name: spellingbee-ui
  namespace: spellingbee
data:
  nginx.conf: |
    events {}
    http {
      server {
        listen 8080;

        # Serve UI
        location / {
          root /usr/share/nginx/html;
          try_files $uri /index.html;
        }

        # Proxy API to gateway (same-origin, no CORS pain)
        location /api/ {
          proxy_pass http://spellingbee-gateway:8080/;
          proxy_set_header Host $host;
          proxy_set_header X-Real-IP $remote_addr;
          proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        }
      }
    }

  index.html: |
    <!doctype html>
    <html>
    <head>
      <meta charset="utf-8" />
      <meta name="viewport" content="width=device-width, initial-scale=1" />
      <title>Spelling Bee MVP</title>
      <style>
        body { font-family: system-ui, -apple-system, Segoe UI, Roboto, sans-serif; margin: 24px; max-width: 900px; }
        .row { display: flex; gap: 16px; flex-wrap: wrap; }
        .card { border: 1px solid #ddd; border-radius: 12px; padding: 16px; margin: 12px 0; }
        button { padding: 10px 14px; border-radius: 10px; border: 1px solid #bbb; background: #fff; cursor: pointer; }
        button.primary { background: #111; color: #fff; border-color: #111; }
        button:disabled { opacity: 0.5; cursor: not-allowed; }
        textarea { width: 100%; min-height: 120px; }
        input[type="text"] { width: 100%; padding: 10px; border-radius: 10px; border: 1px solid #bbb; }
        .mono { font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, monospace; }
        .ok { color: #0a7; font-weight: 600; }
        .bad { color: #c30; font-weight: 600; }
        .hint { color: #666; }
      </style>
    </head>
    <body>
      <h1>Spelling Bee Assistant (MVP)</h1>

      <div class="card">
        <h2>1) Upload word list image</h2>
        <input id="img" type="file" accept="image/*" />
        <div class="row">
          <button class="primary" id="btnExtract">Extract words (Nemotron VL)</button>
          <button id="btnDemoList">Use demo list</button>
        </div>
        <p id="extractStatus" class="hint"></p>
        <h3>Editable word list</h3>
        <textarea id="wordsBox" placeholder="Words will appear here..."></textarea>
      </div>

      <div class="card">
        <h2>2) Start session</h2>
        <label>Student name</label>
        <input id="studentName" type="text" value="Student" />
        <div class="row">
          <button class="primary" id="btnStart">Start</button>
          <button id="btnSpeakPrompt" disabled>Speak prompt</button>
        </div>

        <p><b>Progress:</b> <span id="progress">-</span> &nbsp; <b>Score:</b> <span id="score">-</span></p>
        <p><b>Word:</b> <span id="word" class="mono">-</span></p>
        <p><b>Prompt:</b> <span id="prompt">-</span></p>
        
        <h3>Spelling Bee Helper Buttons</h3>
        <div class="row">
          <button id="btnRepeatWord" disabled style="font-size: 1.1em; padding: 12px 18px;">üîä Repeat the word</button>
          <button id="btnUseSentence" disabled style="font-size: 1.1em; padding: 12px 18px;">üìù Use it in a sentence</button>
        </div>
        <hr/>
        <p><label><input id="handsFree" type="checkbox" /> <b>Hands-Free Mode</b> ‚Äî auto-listen, check &amp; advance</label></p>
        <div id="hfStatus" style="display:none; padding:10px; border-radius:8px; background:#f0f9f4; margin-top:8px;">
          <p id="hfText" style="margin:4px 0; font-weight:600;">Ready</p>
          <div id="liveTranscript" style="font-size:1.3em; font-family:monospace; min-height:36px; padding:8px; background:#fff; border:2px solid #0a7; border-radius:8px; margin:8px 0; color:#333;"></div>
          <button id="btnHFStop" style="background:#c30; color:#fff; border-color:#c30;">Stop Hands-Free</button>
        </div>
      </div>

      <div class="card">
        <h2>3) Answer</h2>
        <p class="hint" id="micHint">
          <b>Mic not working?</b> Browsers require HTTPS for mic on non-localhost.<br/>
          Fix: <code>microk8s kubectl -n spellingbee port-forward svc/spellingbee-ui 8080:8080</code><br/>
          then open <a href="http://localhost:8080">http://localhost:8080</a><br/>
          Or: Chrome ‚Üí <code>chrome://flags</code> ‚Üí "Insecure origins treated as secure" ‚Üí add your URL.
        </p>

        <div class="row">
          <button class="primary" id="btnRecStart" disabled>Start Recording</button>
          <button id="btnRecStop" disabled>Stop</button>
          <button id="btnSubmit" disabled>Submit Audio</button>
        </div>

        <p><label><input id="useLiveStt" type="checkbox" /> Use Live Transcript (Chrome)</label></p>
        <div class="row">
          <button id="btnLiveStart" disabled>Start Live STT</button>
          <button id="btnLiveStop" disabled>Stop Live STT</button>
        </div>

        <p><b>Transcript:</b></p>
        <input id="transcript" type="text" placeholder="(Optional) If ASR not configured, paste transcript here." />

        <p><b>Result:</b> <span id="result">-</span></p>
        <p><b>Parsed letters:</b> <span id="letters" class="mono">-</span></p>
        <p><b>Feedback:</b> <span id="feedback">-</span></p>
        <div class="row">
          <button id="btnSpeakFeedback" disabled>Speak feedback</button>
        </div>
      </div>

      <script src="/app.js"></script>
    </body>
    </html>

  app.js: |
    const $ = (id) => document.getElementById(id);

    const state = {
      sessionId: null,
      idx: 0,
      total: 0,
      word: null,
      prompt: null,
      mediaRecorder: null,
      chunks: [],
      audioBlob: null,
      speechRec: null,
      handsFreeActive: false,
      micStream: null,
      audioCtx: null,
    };

    /* ‚îÄ‚îÄ TTS via ElevenLabs (through gateway) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ */
    let currentAudio = null;

    async function speak(text) {
      if (!text) return;
      try {
        if (currentAudio) { currentAudio.pause(); currentAudio = null; }
        const res = await fetch("/api/tts", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ text }),
        });
        if (!res.ok) throw new Error(await res.text());
        const blob = await res.blob();
        const url = URL.createObjectURL(blob);
        const audio = new Audio(url);
        currentAudio = audio;
        audio.play();
      } catch (e) {
        console.warn("ElevenLabs TTS failed, falling back to browser:", e);
        if ("speechSynthesis" in window) {
          window.speechSynthesis.cancel();
          const u = new SpeechSynthesisUtterance(text);
          u.rate = 0.9;
          window.speechSynthesis.speak(u);
        }
      }
    }

    function speakAndWait(text) {
      return new Promise(async (resolve) => {
        if (!text) return resolve();
        try {
          if (currentAudio) { currentAudio.pause(); currentAudio = null; }
          const res = await fetch("/api/tts", {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ text }),
          });
          if (!res.ok) throw new Error(await res.text());
          const blob = await res.blob();
          const url = URL.createObjectURL(blob);
          const audio = new Audio(url);
          currentAudio = audio;
          let done = false;
          const finish = () => { if (!done) { done = true; URL.revokeObjectURL(url); resolve(); } };
          audio.onended = finish;
          audio.onerror = finish;
          audio.play();
          setTimeout(finish, Math.max(text.length * 150, 8000));
        } catch (e) {
          console.warn("ElevenLabs TTS failed, falling back to browser:", e);
          if ("speechSynthesis" in window) {
            window.speechSynthesis.cancel();
            const u = new SpeechSynthesisUtterance(text);
            u.rate = 0.9;
            let done = false;
            const finish = () => { if (!done) { done = true; resolve(); } };
            u.onend = finish;
            u.onerror = finish;
            window.speechSynthesis.speak(u);
            setTimeout(finish, Math.max(text.length * 120, 6000));
          } else { resolve(); }
        }
      });
    }

    async function api(path, opts={}) {
      const res = await fetch("/api" + path, opts);
      if (!res.ok) {
        const t = await res.text();
        throw new Error(`${res.status}: ${t}`);
      }
      return res.json();
    }

    function wordsFromBox() {
      const raw = $("wordsBox").value || "";
      return raw.split(/[\n,]+/).map(s => s.trim().toLowerCase()).filter(Boolean);
    }

    function setStatus(el, msg, isErr=false) {
      el.textContent = msg;
      el.style.color = isErr ? "#c30" : "#666";
    }

    function setHFStatus(msg) {
      const el = $("hfText");
      if (el) el.textContent = msg;
    }

    function setLiveTranscript(text) {
      const el = $("liveTranscript");
      if (el) el.textContent = text || "...";
    }

    function updateUI() {
      $("progress").textContent = state.sessionId ? `${state.idx+1} / ${state.total}` : "-";
      $("word").textContent = state.word || "-";
      $("prompt").textContent = state.prompt || "-";
      $("btnSpeakPrompt").disabled = !state.prompt;
      $("btnRepeatWord").disabled = !state.sessionId;
      $("btnUseSentence").disabled = !state.sessionId;
      $("btnRecStart").disabled = !state.sessionId || state.handsFreeActive;
      $("btnLiveStart").disabled = !state.sessionId || !$("useLiveStt").checked;
      const hf = $("hfStatus");
      if (hf) hf.style.display = state.handsFreeActive ? "block" : "none";
    }

    /* -- VAD Recording ----------------------------------------- */
    function cleanupMic() {
      if (state.micStream) {
        state.micStream.getTracks().forEach(t => t.stop());
        state.micStream = null;
      }
      if (state.audioCtx) {
        state.audioCtx.close().catch(() => {});
        state.audioCtx = null;
      }
      state.mediaRecorder = null;
      $('btnRecStop').disabled = true;
    }

    function recordWithVAD() {
      return new Promise(async (resolve, reject) => {
        try {
          const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
          state.micStream = stream;
          const actx = new (window.AudioContext || window.webkitAudioContext)();
          state.audioCtx = actx;
          const analyser = actx.createAnalyser();
          analyser.fftSize = 2048;
          actx.createMediaStreamSource(stream).connect(analyser);
          const buf = new Uint8Array(analyser.fftSize);
          let sil = 0, sp = 0, stopped = false, cap;
          const chunks = [];
          const mr = new MediaRecorder(stream);
          state.mediaRecorder = mr;

          /* Live transcript via browser SpeechRecognition */
          let liveRec = null;
          const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
          if (SR) {
            liveRec = new SR();
            liveRec.continuous = true;
            liveRec.interimResults = true;
            liveRec.lang = 'en-US';
            liveRec.onresult = (evt) => {
              let interim = '', final = '';
              for (let i = 0; i < evt.results.length; i++) {
                const r = evt.results[i];
                if (r.isFinal) final += r[0].transcript;
                else interim += r[0].transcript;
              }
              setLiveTranscript(final + interim || '...');
            };
            liveRec.onerror = () => {};
            try { liveRec.start(); } catch(e) {}
          }
          setLiveTranscript('Listening...');
          mr.ondataavailable = (e) => { if (e.data.size > 0) chunks.push(e.data); };
          mr.onstop = () => {
            stopped = true; if (cap) clearTimeout(cap);
            if (liveRec) try { liveRec.stop(); } catch(e) {}
            cleanupMic();
            resolve(new Blob(chunks, { type: 'audio/webm' }));
          };
          mr.start();
          $('btnRecStop').disabled = false;
          cap = setTimeout(() => {
            if (!stopped && mr.state !== 'inactive') { stopped = true; mr.stop(); }
          }, 30000);
          (function tick() {
            if (stopped || mr.state === 'inactive') return;
            analyser.getByteTimeDomainData(buf);
            let s = 0;
            for (let i = 0; i < buf.length; i++) { const v=(buf[i]-128)/128; s+=v*v; }
            const rms = Math.sqrt(s / buf.length) * 100;
            if (rms > 3) { sp++; sil = 0; }
            else if (sp > 15) { sil++; }
            if (sil > 50 && sp > 15) {
              stopped = true; clearTimeout(cap);
              setHFStatus('Processing...');
              mr.stop(); return;
            }
            requestAnimationFrame(tick);
          })();
        } catch (e) { reject(e); }
      });
    }

    /* -- Hands-Free Loop ---------------------------------------- */
    async function handsFreeLoop() {
      if (!state.handsFreeActive || !state.sessionId) return;
      setHFStatus("Speaking prompt...");
      await speakAndWait(state.prompt);
      if (!state.handsFreeActive) return;
      await new Promise(r => setTimeout(r, 600));
      if (!state.handsFreeActive) return;
      setHFStatus("Listening... spell the word!");
      let blob;
      try { blob = await recordWithVAD(); } catch (e) {
        setHFStatus("Mic error: " + e.message);
        state.handsFreeActive = false; updateUI(); return;
      }
      if (!state.handsFreeActive) return;
      setHFStatus("Checking answer...");
      try {
        const fd = new FormData();
        fd.append("session_id", state.sessionId);
        fd.append("audio", blob, "answer.webm");
        const data = await api("/turn/answer", { method: "POST", body: fd });
        $("result").innerHTML = data.correct
          ? '<span class="ok">Correct!</span>'
          : '<span class="bad">Incorrect</span>';
        $("letters").textContent = data.letters || "";
        $("feedback").textContent = data.feedback_text || "";
        $("score").textContent = data.score_correct + " / " + data.score_total;
        $("transcript").value = "";
        setHFStatus("Speaking feedback...");
        await speakAndWait(data.feedback_text);
        if (data.done) {
          setHFStatus("All done! Great job!");
          state.handsFreeActive = false;
          state.prompt = "All done!"; state.word = "";
          updateUI(); return;
        }
        await ask(); updateUI();
        await new Promise(r => setTimeout(r, 800));
        handsFreeLoop();
      } catch (e) {
        setHFStatus("Error: " + e.message);
        state.handsFreeActive = false; updateUI();
      }
    }

    // 1) Extract words
    $("btnExtract").onclick = async () => {
      const f = $("img").files?.[0];
      if (!f) return setStatus($("extractStatus"), "Pick an image first.", true);
      setStatus($("extractStatus"), "Extracting with Nemotron VL...");
      try {
        const fd = new FormData();
        fd.append("file", f);
        const data = await api("/extract_words", { method: "POST", body: fd });
        $("wordsBox").value = (data.words || []).join("\n");
        setStatus($("extractStatus"), `Extracted ${data.words.length} words.`);
      } catch (e) {
        setStatus($("extractStatus"), "Extraction failed: " + e.message, true);
      }
    };

    $("btnDemoList").onclick = () => {
      $("wordsBox").value = ["rhythm","necessary","accommodate","beautiful","calendar"].join("\n");
      setStatus($("extractStatus"), "Loaded demo list.");
    };

    // 2) Start session
    $("btnStart").onclick = async () => {
      const words = wordsFromBox();
      if (!words.length) return alert("Add words first.");
      try {
        const data = await api("/session/start", {
          method: "POST",
          headers: {"Content-Type":"application/json"},
          body: JSON.stringify({ words, student_name: $("studentName").value || "Student" })
        });
        state.sessionId = data.session_id;
        state.idx = data.idx;
        state.word = data.word;
        state.total = data.total;
        $("score").textContent = "0 / 0";
        $("result").textContent = "-";
        $("letters").textContent = "-";
        $("feedback").textContent = "-";
        await ask();
        if ($("handsFree").checked) {
          state.handsFreeActive = true;
          updateUI();
          handsFreeLoop();
        } else {
          speak(state.prompt);
        }
      } catch (e) {
        alert("Start failed: " + e.message);
      }
    };

    async function ask() {
      const fd = new FormData();
      fd.append("session_id", state.sessionId);
      const data = await api("/turn/ask", { method: "POST", body: fd });
      state.idx = data.idx;
      state.word = data.word;
      state.prompt = data.prompt_text;
      updateUI();
    }

    $("btnSpeakPrompt").onclick = () => speak(state.prompt);

    // Repeat the word button
    $("btnRepeatWord").onclick = () => {
      if (state.word) {
        speak(state.word);
      }
    };

    // Use it in a sentence button
    $("btnUseSentence").onclick = async () => {
      if (!state.sessionId) return;
      try {
        const fd = new FormData();
        fd.append("session_id", state.sessionId);
        const data = await api("/turn/sentence", { method: "POST", body: fd });
        if (data.sentence) {
          // Speak the sentence but do NOT display it
          speak(data.sentence);
        }
      } catch (e) {
        alert("Failed to generate sentence: " + e.message);
      }
    };

    // 3) Record audio (manual mode)
    $("btnRecStart").onclick = async () => {
      if (state.handsFreeActive) return;
      state.chunks = [];
      state.audioBlob = null;

      let stream;
      try {
        stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      } catch (err) {
        alert("Microphone access blocked!\n\n" +
              "Browsers require HTTPS for mic access on non-localhost.\n\n" +
              "Fix options:\n" +
              "1) Port-forward: microk8s kubectl -n spellingbee port-forward svc/spellingbee-ui 8080:8080\n" +
              "   then open http://localhost:8080\n\n" +
              "2) Chrome flag: chrome://flags ‚Üí 'Insecure origins treated as secure'\n" +
              "   ‚Üí add http://192.168.1.75:30080");
        return;
      }
      const mr = new MediaRecorder(stream);
      state.mediaRecorder = mr;

      mr.ondataavailable = (e) => { if (e.data.size > 0) state.chunks.push(e.data); };
      mr.onstop = () => {
        state.audioBlob = new Blob(state.chunks, { type: "audio/webm" });
        stream.getTracks().forEach(t => t.stop());
        $("btnSubmit").disabled = false;
        $("btnRecStart").disabled = false;
        $("btnRecStop").disabled = true;
      };

      mr.start();
      $("btnRecStart").disabled = true;
      $("btnRecStop").disabled = false;
      $("btnSubmit").disabled = true;
    };

    $("btnRecStop").onclick = () => {
      if (state.mediaRecorder && state.mediaRecorder.state !== "inactive") {
        state.mediaRecorder.stop();
      }
    };

    // Optional live transcript (Chrome)
    function initSpeechRec() {
      const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
      if (!SR) return null;
      const rec = new SR();
      rec.continuous = true;
      rec.interimResults = true;
      rec.lang = "en-US";
      rec.onresult = (evt) => {
        let finalText = "";
        for (let i = evt.resultIndex; i < evt.results.length; i++) {
          const r = evt.results[i];
          if (r.isFinal) finalText += r[0].transcript + " ";
        }
        if (finalText.trim()) $("transcript").value = finalText.trim();
      };
      return rec;
    }

    $("useLiveStt").onchange = () => {
      const enabled = $("useLiveStt").checked;
      $("btnLiveStart").disabled = !enabled || !state.sessionId;
      $("btnLiveStop").disabled = true;
      if (enabled && !state.speechRec) state.speechRec = initSpeechRec();
      if (enabled && !state.speechRec) alert("Live transcript not supported in this browser. Use Chrome or upload audio.");
    };

    $("btnLiveStart").onclick = () => {
      if (!state.speechRec) return;
      state.speechRec.start();
      $("btnLiveStart").disabled = true;
      $("btnLiveStop").disabled = false;
    };
    $("btnLiveStop").onclick = () => {
      if (!state.speechRec) return;
      state.speechRec.stop();
      $("btnLiveStart").disabled = false;
      $("btnLiveStop").disabled = true;
    };

    // Submit answer
    $("btnSubmit").onclick = async () => {
      try {
        const fd = new FormData();
        fd.append("session_id", state.sessionId);

        if (state.audioBlob) {
          fd.append("audio", state.audioBlob, "answer.webm");
        }
        const tx = $("transcript").value || "";
        if (tx.trim()) fd.append("transcript", tx.trim());

        const data = await api("/turn/answer", { method: "POST", body: fd });

        $("result").innerHTML = data.correct ? '<span class="ok">Correct</span>' : '<span class="bad">Incorrect</span>';
        $("letters").textContent = data.letters || "(none)";
        $("feedback").textContent = data.feedback_text || "";
        $("btnSpeakFeedback").disabled = !data.feedback_text;

        $("score").textContent = `${data.score_correct} / ${data.score_total}`;

        if (data.done) {
          state.prompt = "All done!";
          state.word = "";
          updateUI();
          speak(data.feedback_text);
          return;
        }

        await ask();
        speak(state.prompt);

      } catch (e) {
        alert("Submit failed: " + e.message + "\n\nIf ASR isn't configured, enable Live Transcript or type transcript manually.");
      }
    };

    $("btnSpeakFeedback").onclick = () => speak($("feedback").textContent);

    $("btnHFStop").onclick = () => {
      state.handsFreeActive = false;
      cleanupMic();
      if (currentAudio) { currentAudio.pause(); currentAudio = null; }
      window.speechSynthesis.cancel();
      setHFStatus("Stopped.");
      updateUI();
    };

    updateUI();
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spellingbee-ui
  namespace: spellingbee
spec:
  replicas: 1
  selector:
    matchLabels: { app: spellingbee-ui }
  template:
    metadata:
      labels: { app: spellingbee-ui }
    spec:
      nodeSelector:
        kubernetes.io/hostname: controller
      containers:
        - name: nginx
          image: nginx:1.27-alpine
          ports:
            - containerPort: 8080
          volumeMounts:
            - name: ui
              mountPath: /usr/share/nginx/html/index.html
              subPath: index.html
            - name: ui
              mountPath: /usr/share/nginx/html/app.js
              subPath: app.js
            - name: ui
              mountPath: /etc/nginx/nginx.conf
              subPath: nginx.conf
      volumes:
        - name: ui
          configMap:
            name: spellingbee-ui
---
apiVersion: v1
kind: Service
metadata:
  name: spellingbee-ui
  namespace: spellingbee
spec:
  type: NodePort
  selector: { app: spellingbee-ui }
  ports:
    - name: http
      port: 8080
      targetPort: 8080
      nodePort: 30080
---
# -----------------------
# Gateway (FastAPI)
# -----------------------
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spellingbee-gateway
  namespace: spellingbee
spec:
  replicas: 1
  selector:
    matchLabels: { app: spellingbee-gateway }
  template:
    metadata:
      labels: { app: spellingbee-gateway }
    spec:
      nodeSelector:
        kubernetes.io/hostname: controller
      containers:
        - name: gateway
          image: localhost:32000/spellingbee-gateway:0.2
          imagePullPolicy: Always
          env:
            - name: VLLM_TEXT_BASE
              value: "http://vllm-llama-31-8b:8000/v1"
            - name: VLLM_TEXT_MODEL
              value: "nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-NVFP4"
            - name: VLLM_VL_BASE
              value: "http://vllm-nemotron-vl:5566/v1"
            - name: VLLM_VL_MODEL
              value: "nvidia/NVIDIA-Nemotron-Nano-12B-v2-VL-FP8"
            - name: ELEVENLABS_API_KEY
              valueFrom:
                secretKeyRef:
                  name: elevenlabs-key
                  key: api-key
            - name: ELEVENLABS_VOICE_ID
              value: "21m00Tcm4TlvDq8ikWAM"
            - name: ELEVENLABS_MODEL_ID
              value: "eleven_flash_v2_5"
          ports:
            - containerPort: 8080
          readinessProbe:
            httpGet: { path: /healthz, port: 8080 }
            initialDelaySeconds: 3
            periodSeconds: 5
          livenessProbe:
            httpGet: { path: /healthz, port: 8080 }
            initialDelaySeconds: 10
            periodSeconds: 10
---
apiVersion: v1
kind: Service
metadata:
  name: spellingbee-gateway
  namespace: spellingbee
spec:
  type: ClusterIP
  selector: { app: spellingbee-gateway }
  ports:
    - name: http
      port: 8080
      targetPort: 8080

# -----------------------
# OPTIONAL: GPU vLLM - Llama 3.1 8B (text)
# -----------------------
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm-llama-31-8b
  namespace: spellingbee
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels: { app: vllm-llama-31-8b }
  template:
    metadata:
      labels: { app: vllm-llama-31-8b }
    spec:
      runtimeClassName: nvidia
      nodeSelector:
        nvidia.com/gpu.product: NVIDIA-GB10
      containers:
        - name: vllm
          image: ghcr.io/elizabetht/token-labs/vllm-serve:v0.4.0  # DGX Spark-validated (alt: scitrera/dgx-spark-vllm:0.14.0-t4)
          ports:
            - containerPort: 8000
          env:
            - name: HF_TOKEN
              valueFrom:
                secretKeyRef:
                  name: hf-token
                  key: token
            - name: HUGGING_FACE_HUB_TOKEN
              valueFrom:
                secretKeyRef:
                  name: hf-token
                  key: token
            - name: FLASHINFER_DISABLE_VERSION_CHECK
              value: "1"
          resources:
            limits:
              nvidia.com/gpu: 1
          args:
            - "meta-llama/Llama-3.1-8B-Instruct"
            - "--trust-remote-code"
            - "--gpu-memory-utilization"
            - "0.3"
            - "--attention-backend"
            - "FLASHINFER"
            - "--port"
            - "8000"
          volumeMounts:
            - name: hf-cache
              mountPath: /root/.cache/huggingface
      volumes:
        - name: hf-cache
          emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: vllm-llama-31-8b
  namespace: spellingbee
spec:
  type: ClusterIP
  selector: { app: vllm-llama-31-8b }
  ports:
    - name: http
      port: 8000
      targetPort: 8000

# -----------------------
# OPTIONAL: GPU vLLM - Nemotron Nano 12B v2 VL (vision-language)
# Port 5566 matches vLLM recipe defaults.
# -----------------------
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm-nemotron-vl
  namespace: spellingbee
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels: { app: vllm-nemotron-vl }
  template:
    metadata:
      labels: { app: vllm-nemotron-vl }
    spec:
      runtimeClassName: nvidia
      nodeSelector:
        nvidia.com/gpu.product: NVIDIA-GB10
      containers:
        - name: vllm
          image: ghcr.io/elizabetht/token-labs/vllm-serve:v0.4.0  # DGX Spark-validated (alt: scitrera/dgx-spark-vllm:0.14.0-t4)
          ports:
            - containerPort: 5566
          env:
            - name: HF_TOKEN
              valueFrom:
                secretKeyRef:
                  name: hf-token
                  key: token
            - name: HUGGING_FACE_HUB_TOKEN
              valueFrom:
                secretKeyRef:
                  name: hf-token
                  key: token
            - name: VLLM_VIDEO_LOADER_BACKEND
              value: "opencv"
            - name: FLASHINFER_DISABLE_VERSION_CHECK
              value: "1"
          resources:
            limits:
              nvidia.com/gpu: 1
          args:
            - "nvidia/NVIDIA-Nemotron-Nano-12B-v2-VL-FP8"
            - "--trust-remote-code"
            - "--gpu-memory-utilization"
            - "0.3"
            - "--attention-backend"
            - "FLASHINFER"
            - "--port"
            - "5566"
          volumeMounts:
            - name: hf-cache
              mountPath: /root/.cache/huggingface
      volumes:
        - name: hf-cache
          emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: vllm-nemotron-vl
  namespace: spellingbee
spec:
  type: ClusterIP
  selector: { app: vllm-nemotron-vl }
  ports:
    - name: http
      port: 5566
      targetPort: 5566

