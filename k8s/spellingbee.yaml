apiVersion: v1
kind: Namespace
metadata:
  name: spellingbee
---
# -----------------------
# UI (nginx + static files â€” built from ui/ directory)
# -----------------------
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spellingbee-ui
  namespace: spellingbee
spec:
  replicas: 1
  selector:
    matchLabels: { app: spellingbee-ui }
  template:
    metadata:
      labels: { app: spellingbee-ui }
    spec:
      nodeSelector:
        kubernetes.io/hostname: controller
      containers:
        - name: nginx
          image: localhost:32000/spellingbee-ui:0.1
          imagePullPolicy: Always
          ports:
            - containerPort: 8080
---
apiVersion: v1
kind: Service
metadata:
  name: spellingbee-ui
  namespace: spellingbee
spec:
  type: NodePort
  selector: { app: spellingbee-ui }
  ports:
    - name: http
      port: 8080
      targetPort: 8080
      nodePort: 30080
---
# -----------------------
# Gateway (FastAPI)
# -----------------------
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spellingbee-gateway
  namespace: spellingbee
spec:
  replicas: 1
  selector:
    matchLabels: { app: spellingbee-gateway }
  template:
    metadata:
      labels: { app: spellingbee-gateway }
    spec:
      nodeSelector:
        kubernetes.io/hostname: controller
      containers:
        - name: gateway
          image: localhost:32000/spellingbee-gateway:0.2
          imagePullPolicy: Always
          env:
            - name: VLLM_TEXT_BASE
              value: "http://vllm-llama-31-8b:8000/v1"
            - name: VLLM_TEXT_MODEL
              value: "nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-NVFP4"
            - name: VLLM_VL_BASE
              value: "http://vllm-nemotron-vl:5566/v1"
            - name: VLLM_VL_MODEL
              value: "nvidia/NVIDIA-Nemotron-Nano-12B-v2-VL-FP8"
            - name: MAGPIE_TTS_API_KEY
              valueFrom:
                secretKeyRef:
                  name: magpie-tts-key
                  key: api-key
            - name: MAGPIE_TTS_VOICE
              value: "Magpie-Multilingual.EN-US.Sofia"
            - name: ELEVENLABS_API_KEY
              valueFrom:
                secretKeyRef:
                  name: elevenlabs-key
                  key: api-key
                  optional: true
          ports:
            - containerPort: 8080
          readinessProbe:
            httpGet: { path: /healthz, port: 8080 }
            initialDelaySeconds: 3
            periodSeconds: 5
          livenessProbe:
            httpGet: { path: /healthz, port: 8080 }
            initialDelaySeconds: 10
            periodSeconds: 10
---
apiVersion: v1
kind: Service
metadata:
  name: spellingbee-gateway
  namespace: spellingbee
spec:
  type: ClusterIP
  selector: { app: spellingbee-gateway }
  ports:
    - name: http
      port: 8080
      targetPort: 8080

# -----------------------
# OPTIONAL: GPU vLLM - Llama 3.1 8B (text)
# -----------------------
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm-llama-31-8b
  namespace: spellingbee
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels: { app: vllm-llama-31-8b }
  template:
    metadata:
      labels: { app: vllm-llama-31-8b }
    spec:
      runtimeClassName: nvidia
      nodeSelector:
        nvidia.com/gpu.product: NVIDIA-GB10
      containers:
        - name: vllm
          image: ghcr.io/elizabetht/token-labs/vllm-serve:v0.4.0  # DGX Spark-validated (alt: scitrera/dgx-spark-vllm:0.14.0-t4)
          ports:
            - containerPort: 8000
          env:
            - name: HF_TOKEN
              valueFrom:
                secretKeyRef:
                  name: hf-token
                  key: token
            - name: HUGGING_FACE_HUB_TOKEN
              valueFrom:
                secretKeyRef:
                  name: hf-token
                  key: token
            - name: FLASHINFER_DISABLE_VERSION_CHECK
              value: "1"
          resources:
            limits:
              nvidia.com/gpu: 1
          args:
            - "meta-llama/Llama-3.1-8B-Instruct"
            - "--trust-remote-code"
            - "--gpu-memory-utilization"
            - "0.3"
            - "--attention-backend"
            - "FLASHINFER"
            - "--port"
            - "8000"
          volumeMounts:
            - name: hf-cache
              mountPath: /root/.cache/huggingface
      volumes:
        - name: hf-cache
          emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: vllm-llama-31-8b
  namespace: spellingbee
spec:
  type: ClusterIP
  selector: { app: vllm-llama-31-8b }
  ports:
    - name: http
      port: 8000
      targetPort: 8000

# -----------------------
# OPTIONAL: GPU vLLM - Nemotron Nano 12B v2 VL (vision-language)
# Port 5566 matches vLLM recipe defaults.
# -----------------------
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm-nemotron-vl
  namespace: spellingbee
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels: { app: vllm-nemotron-vl }
  template:
    metadata:
      labels: { app: vllm-nemotron-vl }
    spec:
      runtimeClassName: nvidia
      nodeSelector:
        nvidia.com/gpu.product: NVIDIA-GB10
      containers:
        - name: vllm
          image: ghcr.io/elizabetht/token-labs/vllm-serve:v0.4.0  # DGX Spark-validated (alt: scitrera/dgx-spark-vllm:0.14.0-t4)
          ports:
            - containerPort: 5566
          env:
            - name: HF_TOKEN
              valueFrom:
                secretKeyRef:
                  name: hf-token
                  key: token
            - name: HUGGING_FACE_HUB_TOKEN
              valueFrom:
                secretKeyRef:
                  name: hf-token
                  key: token
            - name: VLLM_VIDEO_LOADER_BACKEND
              value: "opencv"
            - name: FLASHINFER_DISABLE_VERSION_CHECK
              value: "1"
          resources:
            limits:
              nvidia.com/gpu: 1
          args:
            - "nvidia/NVIDIA-Nemotron-Nano-12B-v2-VL-FP8"
            - "--trust-remote-code"
            - "--gpu-memory-utilization"
            - "0.3"
            - "--attention-backend"
            - "FLASHINFER"
            - "--port"
            - "5566"
          volumeMounts:
            - name: hf-cache
              mountPath: /root/.cache/huggingface
      volumes:
        - name: hf-cache
          emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: vllm-nemotron-vl
  namespace: spellingbee
spec:
  type: ClusterIP
  selector: { app: vllm-nemotron-vl }
  ports:
    - name: http
      port: 5566
      targetPort: 5566
